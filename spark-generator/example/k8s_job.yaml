#apiVersion: "sparkoperator.k8s.io/v1beta2"
#kind: SparkApplication
#metadata:
#  name: spark-etl
#  namespace: spark-operator
#spec:
#  type: Java
#  mode: cluster
#  image: "vantuan12345/spark_gen:1.0.0"
##  env:
##    - name: SPARK_JOB_CONF_PATH
##      value: "/opt/spark/example/spark_etl_job.yaml"
#  imagePullPolicy: Always
##  mainClass: com.tc.bigdata.tool.app.Processor
##  mainApplicationFile: "local:///opt/spark/spark-build-tool-1.0.0-jar-with-dependencies.jar"
#  mainApplicationFile: "local:///opt/spark/py_job.py"
#  sparkVersion: "3.1.1"
#  restartPolicy:
#    type: Never
#  volumes:
#    - name: "test-volume"
#      hostPath:
#        path: "/tmp"
#        type: Directory
#  driver:
#    cores: 1
#    coreLimit: "1200m"
#    memory: "512m"
#    labels:
#      version: 3.5.1
#      serviceAccount: my-release-spark
#    volumeMounts:
#      - name: "test-volume"
#        mountPath: "/tmp"
#  executor:
#    cores: 1
#    instances: 1
#    memory: "512m"
#    labels:
#      version: 3.5.1
#    volumeMounts:
#      - name: "test-volume"
#        mountPath: "/tmp"
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-pi
  namespace: spark-operator
spec:
  type: Scala
  mode: cluster
  image: "vantuan12345/spark_generator:main"
  imagePullPolicy: Always
  mainApplicationFile: "local:///opt/spark/py_job.py"
  sparkVersion: "3.1.1"
  restartPolicy:
    type: Never
  volumes:
    - name: "test-volume"
      hostPath:
        path: "/tmp"
        type: Directory
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 3.1.1
    serviceAccount: my-release-spark
    volumeMounts:
      - name: "test-volume"
        mountPath: "/tmp"
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    labels:
      version: 3.1.1
    volumeMounts:
      - name: "test-volume"
        mountPath: "/tmp"